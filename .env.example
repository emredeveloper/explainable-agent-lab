# OpenAI-compatible endpoint settings
# For LM Studio, usually: http://localhost:1234/v1
# For Ollama, usually: http://localhost:11434/v1
OPENAI_BASE_URL=http://localhost:1234/v1
OPENAI_API_KEY=local

# Agent defaults
# For LM Studio, use the loaded model's name (e.g. gpt-oss-20b, local-model)
# For Ollama, use the exact model tag (e.g. ministral-3:14b, llama3:8b)
AGENT_MODEL=gpt-oss-20b
AGENT_REASONING_EFFORT=high
AGENT_MAX_STEPS=6
AGENT_RUNS_DIR=runs
AGENT_WORKSPACE=.
AGENT_TEMPERATURE=0.2
AGENT_SQLITE_DB=data/agent.db
